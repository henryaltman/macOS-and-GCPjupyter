{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 667
    },
    "colab_type": "code",
    "id": "JXHCjerWE9Gl",
    "outputId": "d5cb38f7-9c01-498a-951b-df0c92911d1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-gpu==2.0.0rc1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/cf/2fc69ba3e59edc8333e2676fa71b40197718dea7dc1282c79955cf6b2acb/tensorflow_gpu-2.0.0rc1-cp36-cp36m-manylinux2010_x86_64.whl (380.5MB)\n",
      "\u001b[K     |████████████████████████████████| 380.5MB 72kB/s \n",
      "\u001b[?25hCollecting tb-nightly<1.15.0a20190807,>=1.15.0a20190806 (from tensorflow-gpu==2.0.0rc1)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/88/24b5fb7280e74c7cf65bde47c171547fd02afb3840cff41bcbe9270650f5/tb_nightly-1.15.0a20190806-py3-none-any.whl (4.3MB)\n",
      "\u001b[K     |████████████████████████████████| 4.3MB 26.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0rc1) (0.8.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0rc1) (3.0.1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0rc1) (1.16.5)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0rc1) (1.15.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0rc1) (0.8.0)\n",
      "Collecting tf-estimator-nightly<1.14.0.dev2019080602,>=1.14.0.dev2019080601 (from tensorflow-gpu==2.0.0rc1)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/28/f2a27a62943d5f041e4a6fd404b2d21cb7c59b2242a4e73b03d9ba166552/tf_estimator_nightly-1.14.0.dev2019080601-py2.py3-none-any.whl (501kB)\n",
      "\u001b[K     |████████████████████████████████| 501kB 45.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0rc1) (1.11.2)\n",
      "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0rc1) (0.2.2)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0rc1) (3.7.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0rc1) (0.1.7)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0rc1) (1.1.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0rc1) (1.1.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0rc1) (1.0.8)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0rc1) (1.12.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0rc1) (0.33.6)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0rc1) (0.15.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0rc1) (3.1.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0rc1) (41.2.0)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==2.0.0rc1) (2.8.0)\n",
      "Installing collected packages: tb-nightly, tf-estimator-nightly, tensorflow-gpu\n",
      "  Found existing installation: tensorflow-gpu 1.14.0\n",
      "    Uninstalling tensorflow-gpu-1.14.0:\n",
      "      Successfully uninstalled tensorflow-gpu-1.14.0\n",
      "Successfully installed tb-nightly-1.15.0a20190806 tensorflow-gpu-2.0.0rc1 tf-estimator-nightly-1.14.0.dev2019080601\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "tensorboard",
         "tensorflow",
         "tensorflow_estimator"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "!pip install tensorflow-gpu==2.0.0rc1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "chz5b4VGFMLM",
    "outputId": "9980c990-1ff3-4509-92f4-a0d4d43f2679"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-rc1\n",
      "sys.version_info(major=3, minor=6, micro=8, releaselevel='final', serial=0)\n",
      "matplotlib 3.0.3\n",
      "numpy 1.16.5\n",
      "pandas 0.24.2\n",
      "sklearn 0.21.3\n",
      "tensorflow 2.0.0-rc1\n",
      "tensorflow_core.keras 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(sys.version_info)\n",
    "for module in mpl, np, pd, sklearn, tf, keras:\n",
    "    print(module.__name__, module.__version__)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "EMS7Jbd6-T0_",
    "outputId": "4ca7396e-362e-4e54-9b1c-e4a4597e0591"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from ftp://ftp.ncdc.noaa.gov/pub/data/noaa/isd-lite\n",
      "   8192/Unknown - 0s 8us/step/root/some\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "目的：预测某个基站下一小时的主要天气情况、月均和年均的数据可视化以便于工业应用的开发\n",
    "\n",
    "预测功能开发步骤：\n",
    "1，获取某点某个小时的经纬度（赤道每度大概为111千米），并保存方圆 111 公里的基站们（入选基站）同一时刻的数据\n",
    "    经纬度例示：（78.246111\t15.465556）\n",
    "1.1，根据经纬度计算入选基站与改点的距离，然后按距离大小排序，将距离作为初始权重，只计算一次并返回出现过的\n",
    "    基站两两之间的距离表（可以利用有向图模型实现化简）\n",
    "    这是第一个待训练的数据（问题：基站的位置虽然不变，但数据采集不稳定，不一定有改年或者该时刻的数据）\n",
    "    对于不稳定出现的基站数据，在没有该基站的数据的情况下，将权重初始化为零（可以获得不同时刻的权重表）\n",
    "    注意两两之间权重是相互的（实际中有些特征不一定）\n",
    "2，将每个入选基站看作一个n 维向量，（然后利用 wide-deep 模型）\n",
    "3，稀疏特征叉乘（有随着数据集变大，提高精确度的作用）\n",
    "    将数据四舍五入（或者考虑高斯模糊等），变得更离散化，以便于使用 onehot 编码，然后作叉乘，精度与计算量之间要做取舍\n",
    "\n",
    "4，2&3 两种输出的结论，各自先初始化为 50%的权重，将预测值与该基站下一时刻（小时）的实际值作比较，\n",
    "    然后通过训练调整\n",
    "'''\n",
    "\n",
    "\n",
    "# 导入数据集，并划分测试集与验证集\n",
    "\n",
    "\n",
    "# meteorology_1949_path = keras.utils.get_file('/root/1949', 'https://www.ncei.noaa.gov/data/global-hourly/archive/csv/1949.tar.gz', untar=False, md5_hash=None, file_hash=None, cache_subdir='datasets', hash_algorithm='auto', extract=True, archive_format='tar', cache_dir=None)\n",
    "meteorology_some_path = keras.utils.get_file('/root/some', 'ftp://ftp.ncdc.noaa.gov/pub/data/noaa/isd-lite',  md5_hash=None, file_hash=None, cache_subdir='datasets', hash_algorithm='auto', cache_dir=None)\n",
    "print(meteorology_some_path)\n",
    "# print(meteorology_1949_path)\n",
    "# print(housing.DESCR)\n",
    "# print(housing.data.shape)\n",
    "# print(housing.target.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K8t7hCBHA_Qp"
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import os\n",
    "def un_gz(file_name):\n",
    "    \"\"\"ungz zip file\"\"\"\n",
    "    f_name = file_name.replace(\".gz\", \"\")\n",
    "    #获取文件的名称，去掉\n",
    "    g_file = gzip.GzipFile(file_name)\n",
    "    #创建gzip对象\n",
    "    open(f_name, \"wb+\").write(g_file.read())\n",
    "    #gzip对象用read()打开后，写入open()建立的文件中。\n",
    "    g_file.close()\n",
    "    #关闭gzip对象\n",
    "\n",
    "import tarfile\n",
    "def un_tar(file_name):\n",
    "      \n",
    "    tar = tarfile.open(file_name)\n",
    "    names = tar.getnames()\n",
    "    if os.path.isdir(file_name + \"_files\"):\n",
    "        pass\n",
    "    else:\n",
    "        os.mkdir(file_name + \"_files\")\n",
    "    #由于解压后是许多文件，预先建立同名文件夹\n",
    "    for name in names:\n",
    "        tar.extract(name, file_name + \"_files/\")\n",
    "    tar.close()\n",
    "\n",
    "\n",
    "# un_gz(\"/root/1949.csv.tar.gz\")\n",
    "# un_tar(\"/root/1949.csv.tar\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "SSkirRe1ktmr",
    "outputId": "1ec5217a-2fd4-4ee5-e7cd-bc2e6eb315d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['STATION', 'LATITUDE', 'LONGITUDE', 'WND', 'CIG', 'VIS', 'DEW', 'SLP',\n",
       "       'MW1', 'TMP'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 99,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meteorology_1949_csv = pd.read_csv(\"/root/1949.csv.tar_files/01199099999.csv\", sep=\",\", usecols=['STATION','LATITUDE','LONGITUDE','WND','CIG','VIS','DEW','SLP','MW1','TMP'])\n",
    "# 改变两列的位置\n",
    "meteorology_1949_csv = meteorology_1949_csv[['STATION','LATITUDE','LONGITUDE','WND','CIG','VIS','DEW','SLP','MW1','TMP']]\n",
    "\n",
    "# 加入入选基站的数据\n",
    "\n",
    "\n",
    "meteorology_1949_csv.head(2)\n",
    "\n",
    "\n",
    "meteorology_1949_csv.columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "n_R7xLi6lJQf",
    "outputId": "3cc3bc49-b3ca-4a17-fbd4-840c65c38913"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(615, 9) (615,)\n",
      "(206, 9) (206,)\n",
      "(274, 9) (274,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train_all, x_test, y_train_all, y_test = train_test_split(\n",
    "    meteorology_1949_csv[['STATION', 'LATITUDE', 'LONGITUDE', 'WND', 'CIG', 'VIS', 'DEW', 'SLP',\n",
    "       'MW1']], meteorology_1949_csv['TMP'], random_state = 7)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "    x_train_all, y_train_all, random_state = 11)\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_valid.shape, y_valid.shape)\n",
    "print(x_test.shape, y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pR8daT-wlLpn"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_valid_scaled = scaler.transform(x_valid)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "xx2Cs5trBmGN",
    "outputId": "5bea66f4-d00a-4774-9855-41968467d093"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_6:0\", shape=(None, 615, 9), dtype=float32)\n",
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, 615, 9)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 615, 10)      100         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 615, 10)      110         dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 615, 19)      0           input_6[0][0]                    \n",
      "                                                                 dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 615, 1)       20          concatenate_5[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 230\n",
      "Trainable params: 230\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# wide-deep 实现\n",
    "# 函数式API 功能API (像函数一样调用keras 的层次)\n",
    "input = keras.layers.Input(shape=x_train.shape)   # 输入层读取数据\n",
    "print(input)\n",
    "\n",
    "# 两层神经网络实现 deep model\n",
    "hidden1 = keras.layers.Dense(10, activation='relu')(input)   # 密集特征 “(input) ”：函数式输入第一层\n",
    "hidden2 = keras.layers.Dense(10, activation='relu')(hidden1)  # 两层是否太多\n",
    "# 像复合函数: f(x) = h(g(x))\n",
    "\n",
    "concat = keras.layers.concatenate([input, hidden2]) # 拼接 wide 和 hidden 的输出[input, hidden2]\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "\n",
    "model = keras.models.Model(inputs = [input],    # 固化以保存模型\n",
    "                           outputs = [output])\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
    "callbacks = [keras.callbacks.EarlyStopping(\n",
    "    patience=5, min_delta=1e-2)]\n",
    "\n",
    "\n",
    "# # 子类API 实现 wide&deep\n",
    "# class WideDeepModel(keras.models.Model):\n",
    "#     def __init__(self):\n",
    "#         super(WideDeepModel, self).__init__()  # 重写\n",
    "#         \"\"\"定义模型的层次\"\"\"\n",
    "#         self.hidden1_layer = keras.layers.Dense(30, activation='relu')  # 第一层\n",
    "#         self.hidden2_layer = keras.layers.Dense(30, activation='relu')\n",
    "#         self.output_layer = keras.layers.Dense(1)\n",
    "#\n",
    "#     def call(self, input):  # 重写\n",
    "#         \"\"\"完成模型的正向计算\"\"\"\n",
    "#         hidden1 = self.hidden1_layer(input)\n",
    "#         hidden2 = self.hidden2_layer(hidden1)\n",
    "#         concat = keras.layers.concatenate([input, hidden2])\n",
    "#         output = self.output_layer(concat)\n",
    "#         return output\n",
    "#\n",
    "#\n",
    "# # model = WideDeepModel()\n",
    "# model = keras.models.Sequential([\n",
    "#     WideDeepModel(),\n",
    "# ])\n",
    "#\n",
    "# model.build(input_shape=(None, 8))\n",
    "#\n",
    "# model.summary()\n",
    "# model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
    "# callbacks = [keras.callbacks.EarlyStopping(\n",
    "#     patience=5, min_delta=1e-2)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MyNpPd2PjYM0"
   },
   "outputs": [],
   "source": [
    "\n",
    "# 多输入\n",
    "input_wide = keras.layers.Input(shape=[5])  # 取前五个feature 作为wide 的输入\n",
    "input_deep = keras.layers.Input(shape=[6])  # 取后六个feature 作为deep 的输入\n",
    "hidden1 = keras.layers.Dense(30, activation='relu')(input_deep)\n",
    "hidden2 = keras.layers.Dense(30, activation='relu')(hidden1)\n",
    "concat = keras.layers.concatenate([input_wide, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.models.Model(inputs=[input_wide, input_deep],  # 作用还是固化上面的模型\n",
    "                           outputs=[output])\n",
    "\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
    "callbacks = [keras.callbacks.EarlyStopping(\n",
    "    patience=5, min_delta=1e-2)]\n",
    "model.summary()\n",
    "\n",
    "# 多输出\n",
    "\n",
    "input_wide = keras.layers.Input(shape=[5])\n",
    "input_deep = keras.layers.Input(shape=[6])\n",
    "hidden1 = keras.layers.Dense(30, activation='relu')(input_deep)\n",
    "hidden2 = keras.layers.Dense(30, activation='relu')(hidden1)\n",
    "concat = keras.layers.concatenate([input_wide, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "output2 = keras.layers.Dense(1)(hidden2)  #####\n",
    "model = keras.models.Model(inputs=[input_wide, input_deep],\n",
    "                           outputs=[output, output2])  ####\n",
    "\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
    "callbacks = [keras.callbacks.EarlyStopping(\n",
    "    patience=5, min_delta=1e-2)]\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# 重新划分数据集\n",
    "x_train_scaled_wide = x_train_scaled[:, :5]\n",
    "x_train_scaled_deep = x_train_scaled[:, 2:]\n",
    "x_valid_scaled_wide = x_valid_scaled[:, :5]\n",
    "x_valid_scaled_deep = x_valid_scaled[:, 2:]\n",
    "x_test_scaled_wide = x_test_scaled[:, :5]\n",
    "x_test_scaled_deep = x_test_scaled[:, 2:]\n",
    "\n",
    "history = model.fit([x_train_scaled_wide, x_train_scaled_deep],\n",
    "                    [y_train, y_train],     #### fit 两个 y\n",
    "                    validation_data = (\n",
    "                        [x_valid_scaled_wide, x_valid_scaled_deep],\n",
    "                        [y_valid, y_valid]),\n",
    "                    epochs = 100,\n",
    "                    callbacks = callbacks)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6o6puIepjqNn"
   },
   "outputs": [],
   "source": [
    "\n",
    "# 训练\n",
    "history = model.fit(x_train, y_train,\n",
    "                    validation_data = (x_valid, y_valid),\n",
    "                    epochs = 100,\n",
    "                    callbacks = callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SuuNCjHdjtzV"
   },
   "outputs": [],
   "source": [
    "\n",
    "# 训练过程可视化\n",
    "def plot_learning_curves(history):\n",
    "    pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "    plt.grid(True)\n",
    "    plt.gca().set_ylim(0, 1)\n",
    "    plt.show()\n",
    "plot_learning_curves(history)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-sXHYPVrjwQc"
   },
   "outputs": [],
   "source": [
    "# 模型在测试集上运行评估\n",
    "model.evaluate(x_test_scaled, y_test)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "meteorology_wide_deep.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
